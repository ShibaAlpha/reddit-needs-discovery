#!/usr/bin/env python3
"""
Reddit Data Crawler for Needs Discovery
é‡‡é›†14ä¸ªSubredditsçš„å¸–å­å’Œè¯„è®º
"""

import praw
import json
import time
import os
from datetime import datetime
from pathlib import Path
import sqlite3

# é…ç½®
SUBREDDITS = [
    'iOSProgramming', 'productivity',  # å¼€å‘/æ•ˆç‡
    'investing', 'FIREUK', 'UKPersonalFinance',  # ç†è´¢
    'Notion', 'bulletjournal',  # å­¦ä¹ /ç¬”è®°
    'running', 'fitness',  # å¥åº·
    'travelhacks', 'Flights',  # æ—…è¡Œ
    'IWantToBuy', 'lifehacks', 'legaladviceUK'  # å®ç”¨
]

OUTPUT_DIR = Path('/Users/openclaw-bot/.openclaw/workspace/reddit-needs-discovery/data')

# æ•°æ®åº“è·¯å¾„
DB_PATH = OUTPUT_DIR / 'reddit_posts.db'

def init_database():
    """åˆå§‹åŒ–SQLiteæ•°æ®åº“"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    # åˆ›å»ºå¸–å­è¡¨
    c.execute('''
        CREATE TABLE IF NOT EXISTS posts (
            id TEXT PRIMARY KEY,
            subreddit TEXT,
            title TEXT,
            selftext TEXT,
            author TEXT,
            created_utc REAL,
            ups INTEGER,
            downs INTEGER,
            score INTEGER,
            num_comments INTEGER,
            is_self BOOLEAN,
            flair TEXT,
            url TEXT,
            collected_at TEXT
        )
    ''')
    
    # åˆ›å»ºè¯„è®ºè¡¨
    c.execute('''
        CREATE TABLE IF NOT EXISTS comments (
            id TEXT PRIMARY KEY,
            post_id TEXT,
            subreddit TEXT,
            author TEXT,
            body TEXT,
            created_utc REAL,
            score INTEGER,
            parent_id TEXT,
            is_top_level BOOLEAN,
            collected_at TEXT
        )
    ''')
    
    # åˆ›å»ºç´¢å¼•
    c.execute('CREATE INDEX IF NOT EXISTS idx_subreddit ON posts(subreddit)')
    c.execute('CREATE INDEX IF NOT EXISTS idx_created ON posts(created_utc DESC)')
    c.execute('CREATE INDEX IF NOT EXISTS idx_post_comments ON comments(post_id)')
    
    conn.commit()
    return conn

def get_reddit_client():
    """åˆ›å»ºReddit APIå®¢æˆ·ç«¯ï¼ˆæ— éœ€è®¤è¯ï¼‰"""
    return praw.Reddit(
        client_id=os.environ.get('REDDIT_CLIENT_ID', 'demo'),
        client_secret=os.environ.get('REDDIT_CLIENT_SECRET', 'demo'),
        user_agent='NeedsDiscoveryBot/1.0',
        read_only=True
    )

def collect_posts(reddit, subreddit_name, limit=500):
    """é‡‡é›†å¸–å­"""
    subreddit = reddit.subreddit(subreddit_name)
    
    posts = []
    collected_at = datetime.utcnow().isoformat()
    
    # é‡‡é›†çƒ­é—¨å¸–å­
    for post in subreddit.hot(limit=limit):
        posts.append({
            'id': post.id,
            'subreddit': subreddit_name,
            'title': post.title,
            'selftext': post.selftext[:5000] if post.selftext else '',  # é™åˆ¶é•¿åº¦
            'author': str(post.author) if post.author else '[deleted]',
            'created_utc': post.created_utc,
            'ups': post.ups,
            'downs': post.downs,
            'score': post.score,
            'num_comments': post.num_comments,
            'is_self': post.is_self,
            'flair': post.link_flair_text or '',
            'url': post.url,
            'collected_at': collected_at
        })
    
    return posts

def collect_comments(reddit, post_id, limit=20):
    """é‡‡é›†å¸–å­è¯„è®º"""
    submission = reddit.submission(post_id)
    
    comments = []
    collected_at = datetime.utcnow().isoformat()
    
    # æ›¿æ¢æ›´å¤šå›å¤ä»¥è·å–æ‰€æœ‰è¯„è®º
    submission.comments.replace_more(limit=0)
    
    def process_comments(comments_list, post_id, subreddit, level=0):
        for comment in comments_list[:limit]:
            if level == 0 or comment.score > 0:  # åªé‡‡é¡¶çº§è¯„è®ºæˆ–é«˜èµè¯„è®º
                comments.append({
                    'id': comment.id,
                    'post_id': post_id,
                    'subreddit': subreddit,
                    'author': str(comment.author) if comment.author else '[deleted]',
                    'body': comment.body[:2000] if comment.body else '',
                    'created_utc': comment.created_utc,
                    'score': comment.score,
                    'parent_id': comment.parent_id,
                    'is_top_level': level == 0,
                    'collected_at': collected_at
                })
            
            # é€’å½’å¤„ç†å›å¤
            if hasattr(comment, 'replies'):
                process_comments(comment.replies, post_id, subreddit, level + 1)
    
    process_comments(submission.comments, post_id, subreddit_name)
    
    return comments

def save_to_db(conn, posts, comments):
    """ä¿å­˜åˆ°SQLiteæ•°æ®åº“"""
    c = conn.cursor()
    
    # ä¿å­˜å¸–å­
    for post in posts:
        c.execute('''
            INSERT OR REPLACE INTO posts 
            (id, subreddit, title, selftext, author, created_utc, ups, downs, score, num_comments, is_self, flair, url, collected_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            post['id'], post['subreddit'], post['title'], post['selftext'],
            post['author'], post['created_utc'], post['ups'], post['downs'],
            post['score'], post['num_comments'], post['is_self'], 
            post['flair'], post['url'], post['collected_at']
        ))
    
    # ä¿å­˜è¯„è®º
    for comment in comments:
        c.execute('''
            INSERT OR REPLACE INTO comments 
            (id, post_id, subreddit, author, body, created_utc, score, parent_id, is_top_level, collected_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            comment['id'], comment['post_id'], comment['subreddit'],
            comment['author'], comment['body'], comment['created_utc'],
            comment['score'], comment['parent_id'], comment['is_top_level'],
            comment['collected_at']
        ))
    
    conn.commit()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Reddit Data Crawler - Needs Discovery Project")
    print("=" * 60)
    
    # åˆå§‹åŒ–
    conn = init_database()
    reddit = get_reddit_client()
    
    total_posts = 0
    total_comments = 0
    
    start_time = time.time()
    
    for subreddit in SUBREDDITS:
        print(f"\nğŸ“¦ æ­£åœ¨é‡‡é›† r/{subreddit}...")
        
        try:
            # é‡‡é›†å¸–å­
            posts = collect_posts(reddit, subreddit, limit=500)
            print(f"   é‡‡é›†åˆ° {len(posts)} æ¡å¸–å­")
            
            # é‡‡é›†è¯„è®ºï¼ˆåªé‡‡é«˜èµå¸–å­çš„è¯„è®ºï¼‰
            all_comments = []
            for post in posts[:100]:  # åªé‡‡å‰100ä¸ªå¸–å­çš„è¯„è®º
                try:
                    comments = collect_comments(reddit, post['id'], limit=20)
                    all_comments.extend(comments)
                    time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
                except Exception as e:
                    print(f"   è¯„è®ºé‡‡é›†å¤±è´¥: {e}")
            
            print(f"   é‡‡é›†åˆ° {len(all_comments)} æ¡è¯„è®º")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            save_to_db(conn, posts, all_comments)
            
            total_posts += len(posts)
            total_comments += len(all_comments)
            
            print(f"   âœ… r/{subreddit} å®Œæˆ")
            
        except Exception as e:
            print(f"   âŒ r/{subreddit} å¤±è´¥: {e}")
        
        time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
    
    conn.close()
    
    elapsed = time.time() - start_time
    print("\n" + "=" * 60)
    print(f"ğŸ‰ å®Œæˆï¼å…±é‡‡é›† {total_posts} æ¡å¸–å­ï¼Œ{total_comments} æ¡è¯„è®º")
    print(f"ğŸ“ æ•°æ®ä¿å­˜åœ¨: {DB_PATH}")
    print(f"â±ï¸ ç”¨æ—¶: {elapsed:.1f} ç§’")
    print("=" * 60)

if __name__ == '__main__':
    main()
